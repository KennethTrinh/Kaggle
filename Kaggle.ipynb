{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69619cae-039e-4085-8b43-27192ab42ae8",
   "metadata": {},
   "source": [
    "# Spoken Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162d68a-cd9c-4af5-b86e-e0c516c315f5",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "Before beginning, we need to process the audio files by extracting the wavefile and pairing them with their respective labels. We'd expect the length of the list of all the wave files and labels to be 90,000 each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c4c2c6-9c65-4fc5-bfe8-2a24d62e12b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "90000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "PATH = './train/train_new/train_'\n",
    "TEST_PATH = './test/test_new/test_'\n",
    "\n",
    "def load_speeches(path):\n",
    "    all_waves = []\n",
    "    for i in range(90000):\n",
    "        file = path + str(i) + '.wav'\n",
    "        _, samples = wavfile.read(file)\n",
    "        all_waves.append(samples)\n",
    "    data = pd.read_csv('train.csv')\n",
    "    labels = [data.iloc[:, 1][i] for i in range(90000)]\n",
    "    return all_waves,labels\n",
    "\n",
    "\n",
    "all_waves,labels = load_speeches(PATH)\n",
    "print(len(all_waves))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d5f51-4bf3-40d1-8a4c-31713dbd35e1",
   "metadata": {},
   "source": [
    "Next, we then encode the labels (since there are 6), and pair them with the spectrogram transformation of the audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32428bac-e95f-4e73-90c6-af84bba8017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 129, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import signal\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "def get_spectrograms(waves):\n",
    "    sample_rate = 8000\n",
    "    spectros = []\n",
    "    freqs = []\n",
    "    tims = []\n",
    "    for wav in waves:\n",
    "        frequencies, times, spectrogram = signal.spectrogram(wav, sample_rate)\n",
    "        freqs.append(frequencies)\n",
    "        tims.append(times)\n",
    "        spectros.append(spectrogram)\n",
    "    return freqs,tims,spectros\n",
    "\n",
    "labelencoder = LabelEncoder().fit(labels)\n",
    "encoded_labels = tf.keras.utils.to_categorical(labelencoder.transform(labels), 6)\n",
    "freqs,tims,spectros = get_spectrograms(all_waves)\n",
    "spectros = np.array(spectros)\n",
    "spectros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791357ad-5d93-4637-a07e-5f45ddc0e6fa",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4431ab3c-b191-43e1-8f83-7fd2a6d6d89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 6000)\n",
      "(90000, 6000)\n",
      "(90000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_waves = np.array(all_waves)\n",
    "log_reg_spectros = spectros.reshape(90000, -1)\n",
    "print(log_reg_waves.shape)\n",
    "print(log_reg_waves.shape)\n",
    "print(encoded_labels.shape)\n",
    "\n",
    "encoded_labels = labelencoder.transform(labels)\n",
    "def logistic_regression_accuracy(data, encoded_labels):\n",
    "    X, X_test, Y, Y_test = train_test_split(data, encoded_labels, test_size=0.15, random_state=42)\n",
    "    reg = LogisticRegression().fit(X, Y)\n",
    "    predictions = reg.predict(X_test)\n",
    "    accuracy = reg.score(X_test, Y_test)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0808f343-b3c7-4b16-8df5-998a06eb3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression with wave: 1.0\n",
      "Accuracy for logistic regression with spectrogram: 0.9945925925925926\n"
     ]
    }
   ],
   "source": [
    "wav_accuracy = logistic_regression_accuracy(log_reg_waves, encoded_labels)\n",
    "spectro_accuracy = logistic_regression_accuracy(log_reg_spectros, encoded_labels)\n",
    "print(f'Accuracy for logistic regression with wave: {wav_accuracy}')\n",
    "print(f'Accuracy for logistic regression with spectrogram: {spectro_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224e53ca-fa0b-49db-9127-d39ed63756bb",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73fc96dc-a9b7-4ceb-9faf-03b00f07a9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Naive Bayes with wave: 0.20977777777777779\n",
      "Accuracy for Naive Bayes with spectrogram: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "NB_waves = log_reg_waves\n",
    "NB_spectros = log_reg_spectros\n",
    "\n",
    "encoded_labels = labelencoder.transform(labels)\n",
    "def NB_accuracy(data, encoded_labels):\n",
    "    X, X_test, Y, Y_test = train_test_split(data, encoded_labels, test_size=0.15, random_state=42)\n",
    "    clf = GaussianNB().fit(X, Y)\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    return accuracy\n",
    "\n",
    "wav_accuracy = NB_accuracy(NB_waves, encoded_labels)\n",
    "spectro_accuracy = NB_accuracy(NB_spectros, encoded_labels)\n",
    "print(f'Accuracy for Naive Bayes with wave: {wav_accuracy}')\n",
    "print(f'Accuracy for Naive Bayes with spectrogram: {spectro_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f535d-d33f-4cd9-bbd4-f296f5c8dad0",
   "metadata": {},
   "source": [
    "## Modifications\n",
    "* Append 43 examples and labels to our current training data\n",
    "* These examples were stored in an array named intersection \n",
    "* We should only append labels that were are certain of being '43'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39544e62-32b4-416b-ae23-3c6ead774b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All waves before appending 43 labels: 18000\n",
      "All waves after appending 43 labels: 20229\n"
     ]
    }
   ],
   "source": [
    "PATH = './train/train_new/train_'\n",
    "TEST_PATH = './test/test_new/test_'\n",
    "\n",
    "def load_speeches(path):\n",
    "    all_waves = []\n",
    "    for i in range(18000):\n",
    "        file = path + str(i) + '.wav'\n",
    "        _, samples = wavfile.read(file)\n",
    "        all_waves.append(samples)\n",
    "    data = pd.read_csv('train.csv')\n",
    "    labels = [data.iloc[:, 1][i] for i in range(18000)]\n",
    "    return all_waves,labels\n",
    "def append_43(all_waves, labels, intersection):\n",
    "    for i in intersection:\n",
    "        file = TEST_PATH + str(i) + '.wav'\n",
    "        _, samples = wavfile.read(file)\n",
    "        all_waves.append(samples)\n",
    "        labels.append(43)\n",
    "    return all_waves, labels\n",
    "all_waves,labels = load_speeches(PATH)\n",
    "print(f'All waves before appending 43 labels: {len(all_waves)}')\n",
    "intersection = np.loadtxt('./intersection.txt').astype(int)\n",
    "all_waves, labels = append_43(all_waves, labels, intersection)\n",
    "print(f'All waves after appending 43 labels: {len(all_waves)}')\n",
    "labelencoder = LabelEncoder().fit(labels)\n",
    "encoded_labels = tf.keras.utils.to_categorical(labelencoder.transform(labels), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc5723c4-f042-42c2-bcb8-fd076a45a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression with modified (43) wave: 1.0\n",
      "Accuracy for logistic regression with modified (43) spectrogram: 0.9696869851729819\n",
      "Accuracy for Naive Bayes with modified (43) wave: 0.185502471169687\n",
      "Accuracy for Naive Bayes with modified (43) spectrogram: 0.8520593080724876\n"
     ]
    }
   ],
   "source": [
    "freqs,tims,spectros = get_spectrograms(all_waves)\n",
    "spectros = np.array(spectros)\n",
    "modified_waves = np.array(all_waves)\n",
    "modified_spectros = spectros.reshape(20229, -1)\n",
    "encoded_labels = labelencoder.transform(labels)\n",
    "log_wav_accuracy = logistic_regression_accuracy(modified_waves, encoded_labels)\n",
    "log_spectro_accuracy = logistic_regression_accuracy(modified_spectros, encoded_labels)\n",
    "print(f'Accuracy for logistic regression with modified (43) wave: {log_wav_accuracy}')\n",
    "print(f'Accuracy for logistic regression with modified (43) spectrogram: {log_spectro_accuracy}')\n",
    "NB_wav_accuracy = NB_accuracy(modified_waves, encoded_labels)\n",
    "NB_spectro_accuracy = NB_accuracy(modified_spectros, encoded_labels)\n",
    "print(f'Accuracy for Naive Bayes with modified (43) wave: {NB_wav_accuracy}')\n",
    "print(f'Accuracy for Naive Bayes with modified (43) spectrogram: {NB_spectro_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8862c5-15d5-499e-9bd1-24ca917c721c",
   "metadata": {},
   "source": [
    "## Trying a new model - Convolutional Neural Network\n",
    "* 11 Layers\n",
    "* Max Pooling and Batch Normalization\n",
    "* Fully Connected Layers\n",
    "* Dropout Layers and L2-regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12de0f2f-37c7-4fe1-aeb5-42aee8365593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 125, 22, 32)       832       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 121, 18, 32)       25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 121, 18, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 121, 18, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 60, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 60, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 58, 7, 64)         18496     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 56, 5, 64)         36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 56, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 56, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 2, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 28, 2, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               917504    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 84)                10752     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 84)                336       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 1,045,582\n",
      "Trainable params: 1,044,454\n",
      "Non-trainable params: 1,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "spectros = np.array(spectros) #spectros[0].shape --> (129, 26)\n",
    "spectros = spectros.reshape(len(all_waves), 129, 26, 1)\n",
    "encoded_labels = tf.keras.utils.to_categorical(labelencoder.transform(labels), 6)\n",
    "X, X_test, Y, Y_test = train_test_split(spectros, encoded_labels, test_size=0.15, random_state=98)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (129,26,1), kernel_regularizer=tf.keras.regularizers.l2(0.0005)),\n",
    "tf.keras.layers.Conv2D(filters = 32, kernel_size = 5, strides = 1, use_bias=False),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Activation('relu'),\n",
    "tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
    "tf.keras.layers.Dropout(0.25),\n",
    "tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005)),\n",
    "tf.keras.layers.Conv2D(filters = 64, kernel_size = 3, strides = 1, use_bias=False),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Activation('relu'),\n",
    "tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2),\n",
    "tf.keras.layers.Dropout(0.25),\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(units = 256, use_bias=False),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Activation('relu'),\n",
    "tf.keras.layers.Dense(units = 128, use_bias=False),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Activation('relu'),\n",
    "tf.keras.layers.Dense(units = 84, use_bias=False),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.Activation('relu'),\n",
    "tf.keras.layers.Dropout(0.25),\n",
    "tf.keras.layers.Dense(units = 6, activation = 'softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d375b889-1507-460c-8b4d-751d9939ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "135/135 [==============================] - 99s 725ms/step - loss: 0.7263 - accuracy: 0.7382 - val_loss: 0.4845 - val_accuracy: 0.8250\n",
      "Epoch 2/8\n",
      "135/135 [==============================] - 96s 709ms/step - loss: 0.2386 - accuracy: 0.9245 - val_loss: 0.4893 - val_accuracy: 0.8534\n",
      "Epoch 3/8\n",
      "135/135 [==============================] - 95s 701ms/step - loss: 0.1360 - accuracy: 0.9611 - val_loss: 0.1206 - val_accuracy: 0.9644\n",
      "Epoch 4/8\n",
      "135/135 [==============================] - 93s 690ms/step - loss: 0.0909 - accuracy: 0.9759 - val_loss: 0.2182 - val_accuracy: 0.9328\n",
      "Epoch 5/8\n",
      "135/135 [==============================] - 96s 707ms/step - loss: 0.0690 - accuracy: 0.9838 - val_loss: 0.2550 - val_accuracy: 0.9321\n",
      "Epoch 6/8\n",
      "135/135 [==============================] - 100s 740ms/step - loss: 0.0564 - accuracy: 0.9875 - val_loss: 0.0451 - val_accuracy: 0.9901\n",
      "Epoch 7/8\n",
      "135/135 [==============================] - 93s 690ms/step - loss: 0.0515 - accuracy: 0.9888 - val_loss: 0.0345 - val_accuracy: 0.9941\n",
      "Epoch 8/8\n",
      "135/135 [==============================] - 94s 698ms/step - loss: 0.0428 - accuracy: 0.9916 - val_loss: 0.0265 - val_accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb646ca7c40>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X,Y,batch_size=128,epochs=8,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f116e-73cb-4a32-a81b-2102329f2f21",
   "metadata": {},
   "source": [
    "## Making Predictions (to be submitted on kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6429f57a-9fcd-4c85-ba18-98acfdcdaae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_speeches_test(path):\n",
    "    all_waves = []\n",
    "    for i in range(24750):\n",
    "        file = path + str(i) + '.wav'\n",
    "        _, samples = wavfile.read(file)\n",
    "        all_waves.append(samples)\n",
    "    return all_waves\n",
    "\n",
    "\n",
    "test_waves = load_speeches_test(TEST_PATH)\n",
    "_, _, test_spectros = get_spectrograms(test_waves)\n",
    "test_spectros = np.array(test_spectros)\n",
    "test_spectros = test_spectros.reshape(24750, 129, 26, 1)\n",
    "predictions = model.predict(test_spectros)\n",
    "# decoded_predictions = np.argwhere(predictions ==1 )#[:, 1]\n",
    "inverse_predictions = np.array([ np.array([i, np.argmax(prediction)]) for i, prediction in enumerate(predictions)])\n",
    "inverse_predictions[:, 1] = labelencoder.inverse_transform(inverse_predictions[:, 1]) #len(np.argwhere(inverse_predictions[:, 1] == 43))\n",
    "# for replace in replacements: inverse_predictions[replace][1] = 43\n",
    "df = pd.DataFrame(inverse_predictions, columns=['ID', 'Label'])\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951af32-c8e2-435b-866e-ca0645f04e47",
   "metadata": {},
   "source": [
    "## Ensemble methods\n",
    "* Find the intersection of '43' labels over 51 predictions and retrain convolutional neural net with these labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57c4b90c-d06e-41ce-845b-94b50b3442b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2229,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    2,     3,     7, ..., 24711, 24731, 24742])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions = np.loadtxt(\"./predictions/prediction0.txt\").astype(int).reshape(24750, 1) #shape:(24750, 50)\n",
    "for i in range(1,51):\n",
    "     next_prediction = np.loadtxt(f\"./predictions/prediction{i}.txt\").astype(int).reshape(24750,1)\n",
    "     all_predictions = np.append(all_predictions, next_prediction, axis=1)\n",
    "\n",
    "\n",
    "intersection = np.argwhere(all_predictions[:, 0] ==43).flatten()\n",
    "for i in range(1,51):\n",
    "    pred = np.argwhere(all_predictions[:, i] ==43).flatten()\n",
    "    intersection = np.intersect1d(intersection, pred)\n",
    "    \n",
    "print(intersection.shape)\n",
    "intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa6334-ed60-4240-b3f1-f33bd5b29a68",
   "metadata": {},
   "source": [
    "As expected, approximately 2229/24750 ~ 10% of data have '43' labels.  We use this cummulative intersection to continuously retrain our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
